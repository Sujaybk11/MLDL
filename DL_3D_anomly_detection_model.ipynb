{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/torch-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device: cuda | PyTorch 2.9.1+cu126\n",
      "train: 11953 samples ready âœ…\n",
      "valid: 3197 samples ready âœ…\n",
      "ðŸ“¦ Train batches: 352 | Valid batches: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/23:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 142/352 [11:00<14:23,  4.11s/it, acc=59.90%, loss=0.6034]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/23:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 286/352 [21:05<04:39,  4.23s/it, acc=61.37%, loss=0.5745]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [25:53<00:00,  4.41s/it, acc=62.49%, loss=0.5655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 1 | Val Accuracy: 75.13%\n",
      "ðŸ’¾ Saved best model (acc=75.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [25:45<00:00,  4.39s/it, acc=66.13%, loss=0.5085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 2 | Val Accuracy: 78.82%\n",
      "ðŸ’¾ Saved best model (acc=78.82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3/23:  24%|â–ˆâ–ˆâ–       | 85/352 [06:01<18:42,  4.20s/it, acc=64.95%, loss=0.5023]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3/23:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/352 [11:07<13:19,  4.12s/it, acc=66.53%, loss=0.4797]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [24:38<00:00,  4.20s/it, acc=67.11%, loss=0.4839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 3 | Val Accuracy: 75.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4/23:  35%|â–ˆâ–ˆâ–ˆâ–      | 122/352 [08:29<15:50,  4.13s/it, acc=64.49%, loss=0.4570]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4/23:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 124/352 [08:38<15:45,  4.15s/it, acc=64.73%, loss=0.4569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4/23:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 213/352 [14:48<09:43,  4.20s/it, acc=65.38%, loss=0.4590]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [24:24<00:00,  4.16s/it, acc=67.20%, loss=0.4516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 4 | Val Accuracy: 78.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5/23:  12%|â–ˆâ–        | 41/352 [03:03<21:20,  4.12s/it, acc=68.87%, loss=0.4886] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image2.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5/23:  18%|â–ˆâ–Š        | 64/352 [04:37<19:47,  4.12s/it, acc=66.50%, loss=0.4735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [24:28<00:00,  4.17s/it, acc=69.38%, loss=0.4467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 5 | Val Accuracy: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6/23:  17%|â–ˆâ–‹        | 60/352 [04:09<20:05,  4.13s/it, acc=69.17%, loss=0.4277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6/23:  29%|â–ˆâ–ˆâ–‰       | 103/352 [07:06<17:08,  4.13s/it, acc=69.33%, loss=0.4248]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image3.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [24:10<00:00,  4.12s/it, acc=69.17%, loss=0.3991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 6 | Val Accuracy: 76.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7/23:  22%|â–ˆâ–ˆâ–       | 79/352 [05:28<18:44,  4.12s/it, acc=69.40%, loss=0.3887]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Failed to open: /mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png err: cannot identify image file '/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/train/XR_WRIST/patient07840/study2_negative/._image1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7/23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [24:09<00:00,  4.12s/it, acc=70.80%, loss=0.3909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Epoch 7 | Val Accuracy: 76.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8/23:   3%|â–Ž         | 9/352 [00:43<24:51,  4.35s/it, acc=71.57%, loss=0.3904]"
     ]
    }
   ],
   "source": [
    "# === FULL WORKING TRAINING PIPELINE (MURA or any X-ray dataset) ===\n",
    "import os, time, gc, re, torch, warnings\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import timm\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "PROJECT_ROOT = str(Path.cwd())\n",
    "DATASET_DIRNAME = \"MURA-v1.1\"  # change if needed\n",
    "TRAIN_IMG_PATHS_CSV = \"MURA-v1.1/train_image_paths.csv\"\n",
    "VALID_IMG_PATHS_CSV = \"MURA-v1.1/valid_image_paths.csv\"\n",
    "IMG_SIZE = 320\n",
    "BATCH_SIZE = 34\n",
    "NUM_WORKERS = min(4, os.cpu_count() or 2)\n",
    "EPOCHS = 23\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… Device:\", DEVICE, \"| PyTorch\", torch.__version__)\n",
    "\n",
    "# ---------------- DATA PREP ----------------\n",
    "def extract_bone_label(p):\n",
    "    p = str(p).replace(\"\\\\\", \"/\")\n",
    "    bone = re.search(r\"(XR_[A-Z]+)\", p)\n",
    "    study = re.search(r\"(study[^/]+)\", p)\n",
    "    bone = bone.group(1).upper() if bone else \"UNKNOWN\"\n",
    "    label = 1 if \"positive\" in (study.group(1).lower() if study else \"\") else 0\n",
    "    return bone, label\n",
    "\n",
    "def make_full_path(p):\n",
    "    p = str(p).replace(\"\\\\\", \"/\").lstrip(\"./\")\n",
    "    if p.startswith(DATASET_DIRNAME + \"/\"):\n",
    "        return os.path.join(PROJECT_ROOT, p)\n",
    "    elif p.startswith(\"train/\") or p.startswith(\"valid/\"):\n",
    "        return os.path.join(PROJECT_ROOT, DATASET_DIRNAME, p)\n",
    "    else:\n",
    "        return os.path.join(PROJECT_ROOT, DATASET_DIRNAME, p)\n",
    "\n",
    "def build_df(csv_path, split_name):\n",
    "    df = pd.read_csv(csv_path, header=None, names=[\"path\"], dtype=str)\n",
    "    df[[\"bone\", \"label\"]] = df[\"path\"].apply(lambda x: pd.Series(extract_bone_label(x)))\n",
    "    df[\"full_path\"] = df[\"path\"].apply(make_full_path)\n",
    "    df = df[df[\"label\"].notna()].copy().reset_index(drop=True)\n",
    "    # filter missing files\n",
    "    df[\"exists\"] = df[\"full_path\"].apply(os.path.exists)\n",
    "    missing = len(df) - df[\"exists\"].sum()\n",
    "    if missing > 0:\n",
    "        print(f\"âš ï¸ {missing} missing images in {split_name} removed.\")\n",
    "        df = df[df[\"exists\"]].drop(columns=[\"exists\"])\n",
    "    print(f\"{split_name}: {len(df)} samples ready âœ…\")\n",
    "    return df\n",
    "\n",
    "train_df = build_df(TRAIN_IMG_PATHS_CSV, \"train\")\n",
    "valid_df = build_df(VALID_IMG_PATHS_CSV, \"valid\")\n",
    "\n",
    "# ---------------- DATASETS ----------------\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "valid_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "class SafeDataset(Dataset):\n",
    "    def __init__(self, df, tfms):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"full_path\"]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = self.tfms(img)\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ Failed to open:\", path, \"err:\", e)\n",
    "            img = torch.zeros(3, IMG_SIZE, IMG_SIZE)\n",
    "        return img, torch.tensor(int(row[\"label\"]))\n",
    "\n",
    "def make_sampler(df):\n",
    "    counts = df[\"label\"].value_counts().to_dict()\n",
    "    weights = df[\"label\"].map(lambda x: 1.0/counts[x])\n",
    "    return WeightedRandomSampler(torch.DoubleTensor(weights.values),\n",
    "                                 num_samples=len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(SafeDataset(train_df, train_tfms),\n",
    "                          batch_size=BATCH_SIZE, sampler=make_sampler(train_df),\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "valid_loader = DataLoader(SafeDataset(valid_df, valid_tfms),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"ðŸ“¦ Train batches:\", len(train_loader), \"| Valid batches:\", len(valid_loader))\n",
    "\n",
    "# ---------------- MODEL ----------------\n",
    "## model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model = timm.create_model(\"efficientnet_b3\", pretrained=True, num_classes=2)\n",
    "\n",
    "\n",
    "################ chnages ######################################################\n",
    "# Example safe access\n",
    "if hasattr(model, \"classifier\"):\n",
    "    in_feats = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_feats, 2))\n",
    "elif hasattr(model, \"fc\"):\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_feats, 2))\n",
    "elif hasattr(model, \"head\"):\n",
    "    # some timm models use .head\n",
    "    try:\n",
    "        in_feats = model.head.in_features\n",
    "        model.head = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_feats, 2))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "#####  model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(num_ftrs, 2))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "\n",
    "############################################################################################N\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "# ---------------- TRAINING ----------------\n",
    "best_acc = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total = 0, 0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "         ##############################################################################################\n",
    "        mixed_imgs, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "       \n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "             out = model(mixed_imgs)2\n",
    "             loss = mixup_criterion(criterion, out, y_a, y_b, lam)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        total_correct += (out.argmax(1) == labels).sum().item()\n",
    "        total += imgs.size(0)\n",
    "        pbar.set_postfix(loss=f\"{total_loss/total:.4f}\", acc=f\"{100*total_correct/total:.2f}%\")\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\"):\n",
    "        for imgs, labels in valid_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            out = model(imgs)\n",
    "            val_correct += (out.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    print(f\"ðŸ“ˆ Epoch {epoch+1} | Val Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"efficientnet_b3.pth\")\n",
    "        print(f\"ðŸ’¾ Saved best model (acc={best_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete. Best validation accuracy: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b3bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EfficientNet-B3 Loaded Successfully\n",
      "\n",
      "===============================\n",
      "Bone Type: XR_SHOULDER\n",
      "Anomaly: NEGATIVE (Normal)\n",
      "Probabilities: [[0.6723247 0.3276753]]\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import re\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_WEIGHTS = \"efficientnet_b3.pth\"\n",
    "IMAGE_PATH = \"/mnt/c/Users/advan/Downloads/EdgeAi_resistor_Dl_model/MURA-v1.1/valid/XR_SHOULDER/patient11245/study1_positive/image1.png\"\n",
    "IMG_SIZE = 320     # must match your training IMG_SIZE\n",
    "\n",
    "# -------------------------------\n",
    "# SAME TRANSFORMS USED IN TRAINING\n",
    "# -------------------------------\n",
    "tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# EXTRACT BONE TYPE FROM PATH\n",
    "# -------------------------------\n",
    "def extract_bone(path):\n",
    "    path = path.replace(\"\\\\\", \"/\")\n",
    "    match = re.search(r\"(XR_[A-Z]+)\", path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD MODEL (CORRECT ARCHITECTURE)\n",
    "# -------------------------------\n",
    "def load_model():\n",
    "    model = timm.create_model(\n",
    "        \"efficientnet_b3\",\n",
    "        pretrained=False,\n",
    "        num_classes=2\n",
    "    )\n",
    "\n",
    "    # Fix classifier exactly as training\n",
    "    if hasattr(model, \"classifier\"):\n",
    "        in_feats = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_feats, 2)\n",
    "        )\n",
    "    elif hasattr(model, \"fc\"):\n",
    "        in_feats = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_feats, 2)\n",
    "        )\n",
    "    elif hasattr(model, \"head\"):\n",
    "        in_feats = model.head.in_features\n",
    "        model.head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_feats, 2)\n",
    "        )\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_WEIGHTS, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    print(\"âœ… EfficientNet-B3 Loaded Successfully\")\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# PREDICT\n",
    "# -------------------------------\n",
    "def predict(image_path, model):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = tfms(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "        prob = torch.softmax(out, dim=1)\n",
    "        pred = prob.argmax(dim=1).item()\n",
    "\n",
    "    return pred, prob.cpu().numpy()\n",
    "\n",
    "# -------------------------------\n",
    "# RUN\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    bone_type = extract_bone(IMAGE_PATH)\n",
    "\n",
    "    model = load_model()\n",
    "    pred, prob = predict(IMAGE_PATH, model)\n",
    "\n",
    "    anomaly_map = {0: \"NEGATIVE (Normal)\", 1: \"POSITIVE (Abnormal)\"}\n",
    "\n",
    "    print(\"\\n===============================\")\n",
    "    print(\"Bone Type:\", bone_type)\n",
    "    print(\"Anomaly:\", anomaly_map[pred])\n",
    "    print(\"Probabilities:\", prob)\n",
    "    print(\"===============================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
